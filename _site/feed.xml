<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://www.sscit.de/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.sscit.de/" rel="alternate" type="text/html" /><updated>2022-02-10T20:23:24+01:00</updated><id>https://www.sscit.de/feed.xml</id><title type="html">Technology, Future, and Hiking.</title><subtitle>Blog about software development, technological progress and other topics I am interested in.</subtitle><author><name>Stefan Schlichthärle</name></author><entry><title type="html">Hiking Tour to Rubihorn</title><link href="https://www.sscit.de/2021/08/25/hiking-tour-rubihorn.html" rel="alternate" type="text/html" title="Hiking Tour to Rubihorn" /><published>2021-08-25T12:05:31+02:00</published><updated>2021-08-25T12:05:31+02:00</updated><id>https://www.sscit.de/2021/08/25/hiking-tour-rubihorn</id><content type="html" xml:base="https://www.sscit.de/2021/08/25/hiking-tour-rubihorn.html">&lt;p&gt;Hiking up &lt;a href=&quot;https://de.wikipedia.org/wiki/Rubihorn&quot;&gt;Rubihorn&lt;/a&gt; mountain is a popular tour in Oberstdorf. Its quite challenging, as the mountain is nearly 2000 meters high. Nevertheless, the view on top is rewarding and on the way back, you pass the beautiful &lt;em&gt;Gaisalpsee&lt;/em&gt;, which is a very popular destination for hikers starting from &lt;em&gt;Ruby&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;KML File of the tour: &lt;a href=&quot;https://www.sscit.de/assets/tours/rubihorn.kml&quot;&gt;rubihorn.kml&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The path winds up on the south-eastern part of the mountain, therefore be prepared to be exposed to lots of sun. Lots of serpentines, and at the end a very small tightrope walk. From the top, you can already spot the way back towards &lt;em&gt;Gaisalpsee&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.sscit.de/assets/tours/rubihorn1.jpg&quot; alt=&quot;Gaisalpsee&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Gaisalpsee&lt;/em&gt;, as seen from the top of &lt;em&gt;Rubihorn&lt;/em&gt;.&lt;/p&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">Hiking up Rubihorn mountain is a popular tour in Oberstdorf. Its quite challenging, as the mountain is nearly 2000 meters high. Nevertheless, the view on top is rewarding and on the way back, you pass the beautiful Gaisalpsee, which is a very popular destination for hikers starting from Ruby.</summary></entry><entry><title type="html">Hiking Tour to Eissee</title><link href="https://www.sscit.de/2021/08/09/hiking-tour-eissee.html" rel="alternate" type="text/html" title="Hiking Tour to Eissee" /><published>2021-08-09T12:05:31+02:00</published><updated>2021-08-09T12:05:31+02:00</updated><id>https://www.sscit.de/2021/08/09/hiking-tour-eissee</id><content type="html" xml:base="https://www.sscit.de/2021/08/09/hiking-tour-eissee.html">&lt;p&gt;The &lt;a href=&quot;https://www.oberstdorf.de/alpininfo/allgaeuer-alpen/berg-tal/gewaesser/eissee.html&quot;&gt;Eissee&lt;/a&gt; is a very small lake on the northern side of &lt;em&gt;Rauheck&lt;/em&gt; mountain. I took a bike to ride into &lt;em&gt;Oytal&lt;/em&gt;, to avoid a long and rather boring walk until &lt;em&gt;Käseralpe&lt;/em&gt;, before the actual hike starts.&lt;/p&gt;

&lt;p&gt;KML File of the tour: &lt;a href=&quot;https://www.sscit.de/assets/tours/eissee.kml&quot;&gt;eissee.kml&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;From &lt;em&gt;Käseralpe&lt;/em&gt;, &lt;em&gt;Eissee&lt;/em&gt; can be reached by climbing up to &lt;em&gt;Seichereck&lt;/em&gt;, to reach the northern side of the &lt;em&gt;Rauheck&lt;/em&gt; mountain. Be aware, this path is quite challenging, very steep and lots of vegetation that has to be crossed. Pretty lovely view on top, though, as you can look back into &lt;em&gt;Oytal&lt;/em&gt; and the surrounding valleys as well. To reach &lt;em&gt;Eissee&lt;/em&gt;, the path is going down again after &lt;em&gt;Seichereck&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.sscit.de/assets/tours/eissee1.jpg&quot; alt=&quot;On top of Seichereck, looking down to the lake&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On top of &lt;em&gt;Seichereck&lt;/em&gt;, looking down to the lake.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.sscit.de/assets/tours/eissee2.jpg&quot; alt=&quot;Höfats&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Seichereck&lt;/em&gt; also provides an immediate view to &lt;em&gt;Höfats&lt;/em&gt; mountain.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.sscit.de/assets/tours/eissee3.jpg&quot; alt=&quot;Seichereck&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Path on top of &lt;em&gt;Seichereck&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.sscit.de/assets/tours/eissee4.jpg&quot; alt=&quot;Großer Wilder&quot; /&gt;&lt;/p&gt;

&lt;p&gt;View towards &lt;em&gt;Großer Wilder&lt;/em&gt; mountain.&lt;/p&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">The Eissee is a very small lake on the northern side of Rauheck mountain. I took a bike to ride into Oytal, to avoid a long and rather boring walk until Käseralpe, before the actual hike starts.</summary></entry><entry><title type="html">Hiking Tour to Hoher Ifen</title><link href="https://www.sscit.de/2021/07/31/hiking-tour-ifen.html" rel="alternate" type="text/html" title="Hiking Tour to Hoher Ifen" /><published>2021-07-31T12:05:31+02:00</published><updated>2021-07-31T12:05:31+02:00</updated><id>https://www.sscit.de/2021/07/31/hiking-tour-ifen</id><content type="html" xml:base="https://www.sscit.de/2021/07/31/hiking-tour-ifen.html">&lt;p&gt;Together with a friend, I did a tour to &lt;a href=&quot;https://en.wikipedia.org/wiki/Hoher_Ifen&quot;&gt;Hoher Ifen&lt;/a&gt; in Austria, which is the most famous mountain in Kleinwalsertal.&lt;/p&gt;

&lt;p&gt;KML File of the tour: &lt;a href=&quot;https://www.sscit.de/assets/tours/ifen.kml&quot;&gt;ifen.kml&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After climbing up to Hoher Ifen, it is possible to go back to the starting point via Schwarzwasserhütte and the corresponding valley. Its a great tour, unfortunately we had lots of clouds and fog all day, therefore we could not enjoy the view, which is supposed to be astonishing on top.&lt;/p&gt;

&lt;p&gt;Climbing up and down the plateau, where the summit is located, is quite challenging and requires some hiking experience, and good shoes. Both going up and down is via tightrope walk, and partially, the rope is very close to the ground, which means its more like crouching across the trail.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.sscit.de/assets/tours/ifen1.jpg&quot; alt=&quot;View from the Top&quot; /&gt;&lt;/p&gt;

&lt;p&gt;View from the top, well, imagine there are no clouds.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.sscit.de/assets/tours/ifen2.jpg&quot; alt=&quot;At the crag&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Right next to the crag.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.sscit.de/assets/tours/ifen3.jpg&quot; alt=&quot;Ifen plateau&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Behind the clouds, the plateau is supposed to be.&lt;/p&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">Together with a friend, I did a tour to Hoher Ifen in Austria, which is the most famous mountain in Kleinwalsertal.</summary></entry><entry><title type="html">Hiking Tour to Schattenberg</title><link href="https://www.sscit.de/2021/06/13/hiking-tour-schattenberg.html" rel="alternate" type="text/html" title="Hiking Tour to Schattenberg" /><published>2021-06-13T12:05:31+02:00</published><updated>2021-06-13T12:05:31+02:00</updated><id>https://www.sscit.de/2021/06/13/hiking-tour-schattenberg</id><content type="html" xml:base="https://www.sscit.de/2021/06/13/hiking-tour-schattenberg.html">&lt;p&gt;I would like to document and share hiking tours I did in the Bavarian Alps, for the sake of documenting them and inspiring others where to go. Lets start with a short, half-day tour on top of &lt;a href=&quot;https://de.wikipedia.org/wiki/Schattenberg_(Allg%C3%A4uer_Alpen)&quot;&gt;Schattenberg&lt;/a&gt;, which is right next to Oberstorf’s famous Nebelhorn.&lt;/p&gt;

&lt;p&gt;KML File of the tour: &lt;a href=&quot;https://www.sscit.de/assets/tours/schattenberg.kml&quot;&gt;schattenberg.kml&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It takes approx. 2,5 hours from the ski-jumping hill to the summit cross. The trail is quite narrow and steep, but no tightrope walk.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.sscit.de/assets/tours/schattenberg1.jpg&quot; alt=&quot;View from the Top&quot; /&gt;&lt;/p&gt;

&lt;p&gt;View from the top towards Oberstdorf.&lt;/p&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">I would like to document and share hiking tours I did in the Bavarian Alps, for the sake of documenting them and inspiring others where to go. Lets start with a short, half-day tour on top of Schattenberg, which is right next to Oberstorf’s famous Nebelhorn.</summary></entry><entry><title type="html">Trace LSP Communication to Visual Studio Code’s Output Console</title><link href="https://www.sscit.de/2021/04/15/trace-lsp-in-vscode.html" rel="alternate" type="text/html" title="Trace LSP Communication to Visual Studio Code’s Output Console" /><published>2021-04-15T12:05:31+02:00</published><updated>2021-04-15T12:05:31+02:00</updated><id>https://www.sscit.de/2021/04/15/trace-lsp-in-vscode</id><content type="html" xml:base="https://www.sscit.de/2021/04/15/trace-lsp-in-vscode.html">&lt;p&gt;It is possible to trace all language server protocol communication to Visual Studio Code’s output console, as described in the &lt;a href=&quot;https://code.visualstudio.com/api/language-extensions/language-server-extension-guide#logging-support-for-language-server&quot;&gt;developer’s guide&lt;/a&gt;. The explanation in the guide is quite hard to understand, though. In this post, I explain more details about how to configure VSCode’s LSP implementation, so that the traces are printed out.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you are using vscode-languageclient to implement the client, you can specify a setting [langId].trace.server that instructs the Client to log communications between Language Client / Server to a channel of the Language Client’s name.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It took me quite some time to figure out &lt;em&gt;where&lt;/em&gt; to specify the setting (aka &lt;em&gt;configuration option&lt;/em&gt;) mentioned in the user guide. It is possible to define a file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;settings.json&lt;/code&gt; within the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.vscode&lt;/code&gt; folder of your &lt;strong&gt;project&lt;/strong&gt;. In this context, &lt;strong&gt;project&lt;/strong&gt; means the files that are processed by your extension. In case of REL, a &lt;strong&gt;project&lt;/strong&gt; is a set of requirements specification and requirements data files. The configuration option is not specified within your extension development folder. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;settings.json&lt;/code&gt; then contains configuration options that are applied to the running instance of VSCode (and its extensions), that opens the folder.&lt;/p&gt;

&lt;p&gt;If your LSP client extension is based on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;vscode-languageclient&lt;/code&gt;, you can define the setting &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;ClientId.trace.server&quot;: &quot;verbose&quot;&lt;/code&gt; within this file. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ClientId&lt;/code&gt; is defined within the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;extension.js&lt;/code&gt; file, as part of the properties to create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LanguageClient&lt;/code&gt; object (For an example, have a look at &lt;a href=&quot;https://github.com/sscit/rel/blob/main/vscode-ext/extension.js#L28&quot;&gt;REL’s VSCode Extension&lt;/a&gt; )&lt;/p&gt;

&lt;p&gt;The resulting &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;settings.json&lt;/code&gt; then looks like this (assuming no other options are set)&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;RELLanguageClient.trace.server&quot;: &quot;verbose&quot;,
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With the configuration option set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;verbose&lt;/code&gt;, as soon as the folder is opened in Visual Studio Code, all JSON messages to and from the language server are printed into the output console of Visual Studio Code, in a separate channel called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RELLanguageClient&lt;/code&gt;.&lt;/p&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">It is possible to trace all language server protocol communication to Visual Studio Code’s output console, as described in the developer’s guide. The explanation in the guide is quite hard to understand, though. In this post, I explain more details about how to configure VSCode’s LSP implementation, so that the traces are printed out.</summary></entry><entry><title type="html">Applying Bulk Changes to REL Model with Unix Tools</title><link href="https://www.sscit.de/2021/02/27/applying-bulk-changes-to-rel-model.html" rel="alternate" type="text/html" title="Applying Bulk Changes to REL Model with Unix Tools" /><published>2021-02-27T11:05:31+01:00</published><updated>2021-02-27T11:05:31+01:00</updated><id>https://www.sscit.de/2021/02/27/applying-bulk-changes-to-rel-model</id><content type="html" xml:base="https://www.sscit.de/2021/02/27/applying-bulk-changes-to-rel-model.html">&lt;p&gt;One of the design philosophies I was following during the development of the REL framework was to carefully evaluate every feature, whether it is really needed within the framework or if there are already solutions available that can be leveraged. In my professional life, I regularly observe that every software product can be literally destroyed by pressing more and more features into it, to cover every obscure use case (“we always did it like that”) and at the same time sacrificing (code) quality and tests. This leads to unmaintainable software, which is bloated, slow and finally, when the original development team is not available anymore, will be replaced by something new. Focusing on a carefully selected set of features also means that other use cases have to be covered by alternative tools and approaches. The goal should always be to find the most efficient way to tackle a use case, by leveraging methods and tools that are already available and fit best. In today’s blog post, I am writing about bulk changes that have to be applied to the whole requirements model. It’s a use case every requirements engineer is very familiar with and I explain why I didn’t implement dedicated support for this into the framework and rather rely on the use of Unix tools to reach the goal.&lt;/p&gt;

&lt;p&gt;The REL framework does not contain any support to apply bulk changes to the requirements model. A bulk change is required, if for example a new attribute is introduced in the type definition. After introducing it, all existing type instances that are validated with the spec are not valid anymore, because they miss one attribute. Therefore it is necessary to modify all of them, and set a feasible value. Due to the fact that the whole model resides in text files within a repository, the change can easily be applied by using Unix tools like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;find&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt;, which are able to search for patterns in the file, and execute basic operations. Additionally, it can be applied without any risk to destroy data or overload the system. Thanks to Git, a developer can modify its local copy and tweak it until the result is consistent again. Compare this with SQL bulk changes in the production database, which may lead to data loss and emergency roll backs of the database!&lt;/p&gt;

&lt;p&gt;If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt; is not powerful enough (is that really possible?), the next level would be to use REL’s Python integration and write a small script that reads the REL model and prints it out again. That’s more effort for sure, but in this case it’s impossible that the data transformation cannot be resolved, as the script can perform any operation in between. The only aspect to consider in this case is that in order to read the requirements model with Python, it has to be consistent. Therefore the change within specification has to be kept “on hold”, and an inconsistent model has to be printed out first, before the spec change is applied and miraculously, everything gets consistent again.&lt;/p&gt;

&lt;p&gt;In the following paragraphs, I explain a couple of use cases, how to use Linux command line tools and apply bulk changes to a model. I use the &lt;a href=&quot;https://github.com/sscit/rel/tree/main/test/big&quot;&gt;big&lt;/a&gt; test model in REL’s test folder, which contains around 4000 requirements and a decent specification, which allows me to play around with different use cases.&lt;/p&gt;

&lt;h2 id=&quot;deleting-an-attribute-from-specification&quot;&gt;Deleting an Attribute from Specification&lt;/h2&gt;

&lt;p&gt;Let’s assume the requirements team decided to delete one attribute from the &lt;a href=&quot;https://github.com/sscit/rel/blob/main/test/big/spec.rs#L22&quot;&gt;ComponentRequirement&lt;/a&gt; type definition, namely attribute &lt;a href=&quot;https://github.com/sscit/rel/blob/main/test/big/spec.rs#L39&quot;&gt;Is_implemented&lt;/a&gt;. During the course of the project, the team learned that it doesn’t make sense to have this information in the requirements model, because it can be derived out of the linked test cases and the test results.&lt;/p&gt;

&lt;p&gt;Deleting it is trivial, just remove the &lt;a href=&quot;https://github.com/sscit/rel/blob/main/test/big/spec.rs#L39&quot;&gt;line&lt;/a&gt; out of the spec. But what about all the other 4000 requirements, that are now invalid, which also prevents committing the change to the server, because it fails during CI validation? Let’s use the following Linux commands, to modify all files and delete the attribute:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/rel/test/big$ find . -name &quot;*.rd&quot; -type f -exec sed -i -e /Is_implemented/d {} \;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Firstly, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;find&lt;/code&gt; lists all files of type “.rd” and runs &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt; on them. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt; simply removes every line containing “Is_implemented”. To make it even more precise, space and colon that identify an attribute exactly can be included in the command. Checking the difference afterwards with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git diff&lt;/code&gt; ensures that only the expected change has been created, wrong detections can be reverted. No matter how big the project is, this search and replace of the relevant attribute hardly takes a couple of minutes. When I compare this to database tools for requirements engineering, the advantages are obvious: If they do not support bulk changes, it’s your (or the interns) job to replace all occurrences manually. If they do, it’s often restricted to the admins, to prevent damage. If you are the lucky one with privileges to pursue bulk changes, it’s often a delicate story to use the GUI and run the job: What if there is an error, and the whole production data gets a mess? Anyway, not comparable to patching text files locally and committing the delta afterwards without hassle.&lt;/p&gt;

&lt;h2 id=&quot;adding-a-new-attribute-to-type-definition&quot;&gt;Adding a new Attribute to Type Definition&lt;/h2&gt;

&lt;p&gt;Let’s have a look at another typical use case: Type definition &lt;a href=&quot;https://github.com/sscit/rel/blob/main/test/big/spec.rs#L3&quot;&gt;SystemRequirement&lt;/a&gt; is extended with a new attribute. After the owner, a new attribute called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Origin&lt;/code&gt; shall be added, which is either &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Internal&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;External&lt;/code&gt;, depending on the requirement’s origin. Setting all of them to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Internal&lt;/code&gt; is simple:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/rel/test/big/SystemRequirements$ find . -name &quot;*.rd&quot; -type f -exec sed -i -e &quot;/Owner :/a\\    Origin : Internal,&quot; {} \;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Some remarks on that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;First of all, don’t forget the leading whitespace, otherwise the text layout gets broken or another iteration with formatting script is required&lt;/li&gt;
  &lt;li&gt;In this example, we benefit from the fact that all system requirements that shall be modified are located in a folder hierarchy. The tricky aspect is that component requirements also contain the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Owner&lt;/code&gt; attribute, but shall not be modified. How to deal with it, if you cannot rely on the folder structure? Well, in this case, either the condition to look for within &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sed&lt;/code&gt;’s command line has to be more sophisticated, to detect the requirement’s type via regex, or you use the approach sketched above with the Python script, that reads the whole model and writes it back again. While writing it back, you add your custom hooks that trigger only when you are at the right position to introduce the change.&lt;/li&gt;
  &lt;li&gt;In the example, we always add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Internal&lt;/code&gt; to the type instances, but what if it is necessary to evaluate a condition per system requirement to decide about that? My solution at the moment: Add the most likely value to all system requirements, and adapt the others manually afterwards. Depending on the numbers, this approach is often pretty pragmatic and works well. Otherwise, use the Python approach, reading everything and while writing it back, evaluate the condition.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;using-python-script-to-modify-model&quot;&gt;Using Python Script to modify Model&lt;/h2&gt;

&lt;p&gt;As I mentioned already, the most sophisticated approach is to write a Python script that reads the whole model and prints it back. While doing this, you can add your custom hooks to modify at the right position, by e.g. introducing a new attribute. I am thinking about writing the skeleton of such a script and adding it to the framework, which reads everything and writes it back the same way. In this case you can focus on writing the hooks, if you encounter the need to apply a bulk change to the whole model. Another benefit of such a script: It also acts as formatting tool, to remove unintended newlines, whitespaces, wrong indentation etc. After reading the model and writing it back, all files look consistent im terms of coding guidelines.&lt;/p&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">One of the design philosophies I was following during the development of the REL framework was to carefully evaluate every feature, whether it is really needed within the framework or if there are already solutions available that can be leveraged. In my professional life, I regularly observe that every software product can be literally destroyed by pressing more and more features into it, to cover every obscure use case (“we always did it like that”) and at the same time sacrificing (code) quality and tests. This leads to unmaintainable software, which is bloated, slow and finally, when the original development team is not available anymore, will be replaced by something new. Focusing on a carefully selected set of features also means that other use cases have to be covered by alternative tools and approaches. The goal should always be to find the most efficient way to tackle a use case, by leveraging methods and tools that are already available and fit best. In today’s blog post, I am writing about bulk changes that have to be applied to the whole requirements model. It’s a use case every requirements engineer is very familiar with and I explain why I didn’t implement dedicated support for this into the framework and rather rely on the use of Unix tools to reach the goal.</summary></entry><entry><title type="html">Optimizing REL Part 2 - Optimizing the C++ Code</title><link href="https://www.sscit.de/2021/02/13/rel-cpp-optimization.html" rel="alternate" type="text/html" title="Optimizing REL Part 2 - Optimizing the C++ Code" /><published>2021-02-13T18:05:31+01:00</published><updated>2021-02-13T18:05:31+01:00</updated><id>https://www.sscit.de/2021/02/13/rel-cpp-optimization</id><content type="html" xml:base="https://www.sscit.de/2021/02/13/rel-cpp-optimization.html">&lt;p&gt;In the last couple of weeks, I have been focusing on optimizing REL’s C++ implementation, mainly for runtime performance and RAM consumption. In a series of blog posts, I will share my approach on how to measure performance metrics for C++ applications running on Linux, derive conclusions and optimize the code afterwards. This blog post will focus on C++ optimizations I applied to the code.&lt;/p&gt;

&lt;h2 id=&quot;baseline-and-test-data-set&quot;&gt;Baseline and Test Data Set&lt;/h2&gt;

&lt;p&gt;In the &lt;a href=&quot;/2021/02/03/cpp-performance-measurements.html&quot;&gt;last blog post&lt;/a&gt;, I wrote about different tools and approaches, how to measure performance of C++ applications in Linux. I applied them to my implementation of REL, namely the core library and the surrounding CLI wrapper. To get representative values, I defined the &lt;a href=&quot;https://github.com/sscit/rel/tree/main/test/huge&quot;&gt;huge&lt;/a&gt; test data set, which consists of more than 400k requirements, distributed among 225 files, which sum up to around 500 MB. The amount of requirements is way more than even in large software projects, but the specification of this test project is rather simple. Nevertheless, enough food for the software, to spot the impact of different implementations in its measurements.&lt;/p&gt;

&lt;p&gt;Baseline was &lt;a href=&quot;https://github.com/sscit/rel/commit/9fa79fd58bc29eae549abc89e8b48fd4e01bd562&quot;&gt;9fa79fd&lt;/a&gt; and the following values:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Wall Time: 5min 14s
RAM Consumption: 5,7 GB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that the wall time obviously depends a lot on the machine used to measure. As I am currently developing in an Ubuntu VM, the absolute value is not representative at all, but the change over time is for sure. Anyway, the baseline doesn’t look like performant software, 5 minutes for 500 MB of data, and eating up more than 5GB of RAM. These values clearly reflect the state of the software at this point in time, I didn’t apply any optimization, I rather focused on features and clean implementation.&lt;/p&gt;

&lt;h2 id=&quot;optimizing-the-lexer&quot;&gt;Optimizing the Lexer&lt;/h2&gt;

&lt;p&gt;After running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;perf&lt;/code&gt; on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rel_cli&lt;/code&gt; and collecting first measurements, I quickly identified a couple of slow methods within class &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Lexer&lt;/code&gt;: They were called a lot during lexing of the files and consumed significant runtime, due to their poor implementation (see &lt;a href=&quot;https://github.com/sscit/rel/commit/05915cb4982165e6e19dd2cbccdb7433422db01b&quot;&gt;05915cb&lt;/a&gt;). Elimination of copies and using more tailored data structures already made an impact here.&lt;/p&gt;

&lt;p&gt;Additionally, I reworked the overall data flow of the library (see &lt;a href=&quot;https://github.com/sscit/rel/commit/1bdb698fb4c486a1c2471a8223a7f130a6358fad&quot;&gt;1bdb698&lt;/a&gt;). Before, all files were lexed first, and all tokens were stored in memory, which is not necessary at all. An improved workflow goes like this: Reading one file first, creating the tokens, and parsing them afterwards immediately. In this case, the tokens created can be deleted, before starting with the next file. This change alone had a significant impact on RAM consumption.&lt;/p&gt;

&lt;p&gt;After the first iteration of optimizing the code, the new measurements looked like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Wall Time: 2min 47s
RAM Consumption: 2,7 GB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;50% off! Sounds like a good start. There are always low-hanging fruits that can be grabbed easily.&lt;/p&gt;

&lt;h2 id=&quot;eliminating-redundant-copying-of-data&quot;&gt;Eliminating Redundant Copying of Data&lt;/h2&gt;

&lt;p&gt;During the next iteration, I had a look at duplicate data storage within the key data classes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Token&lt;/code&gt; and the ones used in the AST. For example, in all objects of class &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Token&lt;/code&gt;, I stored a string containing the full filename, where the token originated from. Same applied for objects of type &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RdTypeInstance&lt;/code&gt;, which represent a single type instance from the requirements data. For projects consisting of more than 400k requirements, 400k times the size of a string containing a filename indeed makes an impact. I replaced all those occurrences with a pointer to the filename. This optimization, and removing other redundant data, further decreased RAM consumption to less than 1 GB (see &lt;a href=&quot;https://github.com/sscit/rel/commit/921705df19a99372b9742245bfa8801092a65e61&quot;&gt;921705d&lt;/a&gt;). Impact on runtime was only minor though.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Wall Time: 2min 40s
RAM Consumption: 800 MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;using-multiple-threads-to-read-and-parse-requirements-data&quot;&gt;Using Multiple Threads to Read and Parse Requirements Data&lt;/h2&gt;

&lt;p&gt;While testing different configurations and collecting data, I noticed that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rel_cli&lt;/code&gt; was running on a single core only. Of course, it was a single-threaded application, without any code running in parallel, therefore why should it benefit from all cores available in the system? Therefore I made some experiments to parallelize the library: A thread shall be created for every file, which lexes and parses the file and stores the resulting AST elements within the central data structure (see &lt;a href=&quot;https://github.com/sscit/rel/commit/b18f8075686b7631d000d054d3dfd5f2d45c9d8c&quot;&gt;b18f807&lt;/a&gt;). In C++17, spawning multiple threads is quite straightforward. I defined a function closure, which handles a single file. Additionally, to avoid race conditions, I introduced mutexes in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RdParser&lt;/code&gt;, whenever shared data sources are updated. The results were quite whopping: Wall time went further down to nearly one minute only, another improvement by more than 60% compared to the last iteration. But of course, there is no free lunch: Memory consumption increased again significantly, of course, multiple threads in memory means that N files are processed in parallel and the resulting tokens have to be kept in RAM.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Wall Time: 1min 01s
RAM Consumption: 2,4 GB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In REL’s CI validation on Github, that is fortunately based on way more powerful IT compared to my VM, the performance metrics can be seen, too. There the validation of the huge test project went down from approx. 1 minute runtime to less than &lt;a href=&quot;https://github.com/sscit/rel/runs/1849966084&quot;&gt;20s&lt;/a&gt;. With this result, I consider requirement &lt;a href=&quot;https://github.com/sscit/rel/blob/main/requirements/5_performance.rd#L4&quot;&gt;perf1&lt;/a&gt; as fulfilled!&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;To sum up, optimizing C++ code brings tremendous improvements in terms of resource consumptions. It is definitely worth it to spend this effort, because fast software is way more user friendly compared to slow execution times and is a real business value.&lt;/p&gt;

&lt;p&gt;Especially for a tool like REL, which is used by individual users as well as during CI validation, the business value is significant: For the user, optimized code for both RAM and runtime increases productivity and also enables users on “slow” machines, for example virtual machines, to use the tools without frustration. In corporations, where Windows is the dominant operating system, lots of people use Linux via virtual desktop or virtual machine, therefore this environment is a relevant use case. In CI, every second that is saved pays into the overall goal of fast iteration cycles and may helps to reduce cost for the cloud.&lt;/p&gt;

&lt;p&gt;I am still playing around for further optimization. Due to the comprehensive test coverage of REL, introducing further changes imposes a very low risk to break something fundamental. I am still wondering if there is a sweet spot between the number of threads, CPU cores available and the corresponding RAM usage. And I would like to try out if mapping the whole file in memory first may introduce another speed gain.&lt;/p&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">In the last couple of weeks, I have been focusing on optimizing REL’s C++ implementation, mainly for runtime performance and RAM consumption. In a series of blog posts, I will share my approach on how to measure performance metrics for C++ applications running on Linux, derive conclusions and optimize the code afterwards. This blog post will focus on C++ optimizations I applied to the code.</summary></entry><entry><title type="html">Optimizing REL Part 1 - Performance Measurements</title><link href="https://www.sscit.de/2021/02/03/cpp-performance-measurements.html" rel="alternate" type="text/html" title="Optimizing REL Part 1 - Performance Measurements" /><published>2021-02-03T18:05:31+01:00</published><updated>2021-02-03T18:05:31+01:00</updated><id>https://www.sscit.de/2021/02/03/cpp-performance-measurements</id><content type="html" xml:base="https://www.sscit.de/2021/02/03/cpp-performance-measurements.html">&lt;p&gt;In the last couple of weeks, I have been focusing on optimizing REL’s C++ implementation, mainly for runtime performance and RAM consumption. In a series of blog posts, I will share my approach on how to measure performance metrics for C++ applications running on Linux, derive conclusions and optimize the code afterwards. The first article talks about how to measure performance metrics in Linux, which tools are available and how to generate relevant data.&lt;/p&gt;

&lt;h2 id=&quot;performance-kpis&quot;&gt;Performance KPIs&lt;/h2&gt;

&lt;p&gt;Before optimizing an application, it is important to define performance metrics and collect data about current resource consumption. The data helps to identify hotspots, where lots of resources are consumed, and to compare the effect of different measures. Without measurements and data collection, all optimization efforts maybe address aspects that do not make an impact on the overall performance of the software, or make it even worse.&lt;/p&gt;

&lt;p&gt;Useful metrics to collect are for example runtime of the software while processing a realistic data set, or RAM consumption during the same scenario. Depending on your target system, size of the binary or usage of network or other interfaces are maybe relevant KPIs as well. To optimize REL’s C++ implementation, I have been focusing on runtime and RAM consumption.&lt;/p&gt;

&lt;p&gt;Before starting any measurements, it is also important to define a realistic data set. Measurements collected during “idle mode” of the software or in case of REL, with a tiny dataset, won’t provide meaningful insights. Therefore before pursuing measurements, I defined &lt;a href=&quot;https://github.com/sscit/rel/tree/main/test&quot;&gt;test data sets&lt;/a&gt; of different sizes, to ensure that the system gets under load while processing the data.&lt;/p&gt;

&lt;h2 id=&quot;measuring-runtime&quot;&gt;Measuring Runtime&lt;/h2&gt;

&lt;p&gt;Linux Tool &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt; provides an easy way to measure the runtime of a program. Just run it with the program and its parameters:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;time bazel-bin/rel-cli/rel_cli -r ./test/big 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It then returns three values, namely&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;real    0m2.509s
user    0m2.461s
sys	    0m0.032s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;real&lt;/code&gt; describes the time elapsed from start to finish of the program, the so called wall clock time. It includes waiting times and time, where the process was not scheduled at all.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;user&lt;/code&gt; is the time that was actually spent within the user space process, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sys&lt;/code&gt; shows the time spent in the kernel within the process.&lt;/p&gt;

&lt;p&gt;If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt; is run multiple times and with different software versions, a data set can be built up and the effect of changes can be evaluated.&lt;/p&gt;

&lt;h3 id=&quot;identify-expensive-code&quot;&gt;Identify Expensive Code&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt; gives a first indication about the overall runtime, but it does not provide any details about which parts of the code take a long time. To get this kind of information, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;perf&lt;/code&gt; can be used. It executes the process, similar to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;time&lt;/code&gt;, but collects data during execution, which can be used to generate a report afterwards.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo perf record &amp;lt;binary&amp;gt; &amp;lt;binary_options&amp;gt;
sudo perf report
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The report lists functions sorted by their CPU consumption during the execution.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Samples: 2K of event 'cpu-clock:pppH', Event count (approx.): 740750000
Overhead  Command  Shared Object        Symbol
  15.69%  rel_cli  libc-2.31.so         [.] __memcmp_avx2_movbe
  12.55%  rel_cli  rel_cli              [.] std::_Rb_tree&amp;lt;std::__cxx11::basic_string&amp;lt;char, std::char_traits&amp;lt;char&amp;gt;, std::allocator&amp;lt;
   8.64%  rel_cli  rel_cli              [.] Lexer::Read
   4.86%  rel_cli  libstdc++.so.6.0.28  [.] std::istream::get
   3.27%  rel_cli  rel_cli              [.] Lexer::IsOperatorOrKeyword
   3.24%  rel_cli  libstdc++.so.6.0.28  [.] std::__cxx11::basic_string&amp;lt;char, std::char_traits&amp;lt;char&amp;gt;, std::allocator&amp;lt;char&amp;gt; &amp;gt;::compa
   3.17%  rel_cli  libstdc++.so.6.0.28  [.] std::istream::sentry::sentry
   3.10%  rel_cli  libstdc++.so.6.0.28  [.] std::__cxx11::basic_string&amp;lt;char, std::char_traits&amp;lt;char&amp;gt;, std::allocator&amp;lt;char&amp;gt; &amp;gt;::_M_re
   2.73%  rel_cli  libc-2.31.so         [.] __memmove_avx_unaligned_erms
   2.40%  rel_cli  libc-2.31.so         [.] __memmove_avx_unaligned
   2.19%  rel_cli  libc-2.31.so         [.] malloc
   2.16%  rel_cli  libc-2.31.so         [.] _int_malloc
   2.13%  rel_cli  rel_cli              [.] FileReader::GetChar
   1.89%  rel_cli  rel_cli              [.] Lexer::IsOperator
   1.86%  rel_cli  libstdc++.so.6.0.28  [.] std::__cxx11::basic_string&amp;lt;char, std::char_traits&amp;lt;char&amp;gt;, std::allocator&amp;lt;char&amp;gt; &amp;gt;::_M_re
   1.65%  rel_cli  libc-2.31.so         [.] __strlen_avx2
   1.52%  rel_cli  rel_cli              [.] Lexer::IsLinebreak
   1.38%  rel_cli  libstdc++.so.6.0.28  [.] operator new
   1.21%  rel_cli  rel_cli              [.] Lexer::CheckStringandAddToken
   1.18%  rel_cli  rel_cli              [.] SlidingWindow::pop_front
   1.15%  rel_cli  libc-2.31.so         [.] _int_free
   1.15%  rel_cli  libstdc++.so.6.0.28  [.] std::__cxx11::basic_string&amp;lt;char, std::char_traits&amp;lt;char&amp;gt;, std::allocator&amp;lt;char&amp;gt; &amp;gt;::_M_ap
   1.15%  rel_cli  rel_cli              [.] Lexer::AddTokenToList
   1.15%  rel_cli  rel_cli              [.] RdParser::ReadString
   1.11%  rel_cli  libc-2.31.so         [.] cfree@GLIBC_2.2.5
   1.11%  rel_cli  libc-2.31.so         [.] isalnum
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this excerpt, we can see that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rel_cli&lt;/code&gt; application spends most of its time on memcopy operations, due to building up AST and token lists containing lots of strings. Additionally, method &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Read()&lt;/code&gt; within class &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Lexer&lt;/code&gt; is worth investigating. A report like this is very useful to focus on the most expensive methods first, that may offer most potential for optimizations, too. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;perf&lt;/code&gt; tool is pretty straightforward to use, too, and doesn’t require special compilation flags. The release binary including optimized code can be used for analysis.&lt;/p&gt;

&lt;h2 id=&quot;measuring-ram-consumption&quot;&gt;Measuring RAM consumption&lt;/h2&gt;

&lt;p&gt;Another resource that is worth optimizing is the amount of RAM required during execution. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/bin/time/ -v&lt;/code&gt; provides valuable insights on this KPI:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/bin/time -v bazel-bin/rel-cli/rel_cli -r ./test/big 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Besides other information, it returns the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Maximum resident set size (kbytes):&lt;/code&gt;, which indicates the maximum amount of physical RAM allocated by the process during runtime. By running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/bin/time/&lt;/code&gt; multiple times with different software versions, the impact of optimization measures in terms of RAM consumption can be evaluated.&lt;/p&gt;

&lt;p&gt;In the next blog post, I will describe how I evaluated REL’s performance with these tools, and describe measures that improved the KPIs over time.&lt;/p&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">In the last couple of weeks, I have been focusing on optimizing REL’s C++ implementation, mainly for runtime performance and RAM consumption. In a series of blog posts, I will share my approach on how to measure performance metrics for C++ applications running on Linux, derive conclusions and optimize the code afterwards. The first article talks about how to measure performance metrics in Linux, which tools are available and how to generate relevant data.</summary></entry><entry><title type="html">Unit Testing with Google Test in Bazel</title><link href="https://www.sscit.de/2021/01/08/bazel-gtest.html" rel="alternate" type="text/html" title="Unit Testing with Google Test in Bazel" /><published>2021-01-08T18:05:31+01:00</published><updated>2021-01-08T18:05:31+01:00</updated><id>https://www.sscit.de/2021/01/08/bazel-gtest</id><content type="html" xml:base="https://www.sscit.de/2021/01/08/bazel-gtest.html">&lt;p&gt;&lt;a href=&quot;https://github.com/google/googletest&quot;&gt;Google Test&lt;/a&gt; is a well-established framework for unit tests in C++. It provides lots of features and can be used to write tests for own classes and their methods. Its integration in Bazel build system works quite well, with the benefit that it is not necessary to copy Google Test source files into the own repository or use Git submodules, as Google Test’s repository is downloaded on demand by Bazel during the build process. In this blog post, I will describe how &lt;a href=&quot;/2021/01/03/REL.html&quot;&gt;REL&lt;/a&gt; uses Google Test. This approach can easily be transferred to every C++ development project that uses Bazel as build system.&lt;/p&gt;

&lt;p&gt;First of all, Google Test has to be added as external dependency to the Bazel WORKSPACE file. Bazel’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;new_git_repository&lt;/code&gt; rule can be used for this.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;new_git_repository(
    name = &quot;googletest&quot;,
    build_file = &quot;gmock.BUILD&quot;,
    remote = &quot;https://github.com/google/googletest&quot;,
    tag = &quot;release-1.10.0&quot;,
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/sscit/rel/blob/main/WORKSPACE#L3&quot;&gt;Source in REL project&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In this snippet, Google Test’s public repo on Github is referenced, and a dedicated tag is selected. If there is a new version of Google Test available, it is sufficient to update the tag in this rule, to change the dependency for all unit tests in the workspace.&lt;/p&gt;

&lt;p&gt;As a second step, build file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gmock.BUILD&lt;/code&gt; is created in folder &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;external&lt;/code&gt;. It contains the Bazel definitions for Google Test, so that the referenced code is available as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cc_library&lt;/code&gt;’s&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cc_library(
    name = &quot;gtest&quot;,
    srcs = [
        &quot;googletest/src/gtest-all.cc&quot;,
        &quot;googlemock/src/gmock-all.cc&quot;,
    ],
    hdrs = glob([
        &quot;**/*.h&quot;,
        &quot;googletest/src/*.cc&quot;,
        &quot;googlemock/src/*.cc&quot;,
    ]),
    includes = [
        &quot;googlemock&quot;,
        &quot;googletest&quot;,
        &quot;googletest/include&quot;,
        &quot;googlemock/include&quot;,
    ],
    linkopts = [&quot;-pthread&quot;],
    visibility = [&quot;//visibility:public&quot;],
)

cc_library(
    name = &quot;gtest_main&quot;,
    srcs = [&quot;googlemock/src/gmock_main.cc&quot;],
    linkopts = [&quot;-pthread&quot;],
    visibility = [&quot;//visibility:public&quot;],
    deps = [&quot;:gtest&quot;],
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/sscit/rel/blob/main/external/gmock.BUILD&quot;&gt;Source in REL project&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The first library includes all Google Test related source files, whereas the second rule only contains the reference to Google Test’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;main&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;Now Google Test is available in the build environment as external dependency. If it is required as part of a build, it is downloaded and built (and cached) by Bazel. To use it for own unittests, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gtest_main&lt;/code&gt; rule is referenced as dependency by the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cc_test&lt;/code&gt; rule, which also includes the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*Test.cpp&lt;/code&gt; - files, which contain the test cases.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cc_test(
    name = &quot;RelLibUnitTest&quot;,
    srcs = glob([&quot;**/*.cpp&quot;]),
    deps = [
        &quot;//rel-lib:rel_lib&quot;,
        &quot;@googletest//:gtest_main&quot;,
    ],
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/sscit/rel/blob/main/rel-lib/test/unittest/BUILD&quot;&gt;Source in REL project&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cc_test&lt;/code&gt; is the “executable”, which brings together the test cases (in this example, added to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;srcs&lt;/code&gt;), the actual source code that shall be tested (dependency to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rel_lib&lt;/code&gt;) and the Google Test Framework, referenced as dependency, too.&lt;/p&gt;

&lt;p&gt;To run it, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bazel test //path/to:RelLibUnitTest&lt;/code&gt; is executed. Google Test logfiles are not printed out to the command line, they are stored in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/bazel-testlogs/path/to/RelLibUnitTest&lt;/code&gt;.&lt;/p&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">Google Test is a well-established framework for unit tests in C++. It provides lots of features and can be used to write tests for own classes and their methods. Its integration in Bazel build system works quite well, with the benefit that it is not necessary to copy Google Test source files into the own repository or use Git submodules, as Google Test’s repository is downloaded on demand by Bazel during the build process. In this blog post, I will describe how REL uses Google Test. This approach can easily be transferred to every C++ development project that uses Bazel as build system.</summary></entry><entry><title type="html">Building and Testing C++ Python Modules with Bazel</title><link href="https://www.sscit.de/2021/01/05/python-bazel.html" rel="alternate" type="text/html" title="Building and Testing C++ Python Modules with Bazel" /><published>2021-01-05T16:05:31+01:00</published><updated>2021-01-05T16:05:31+01:00</updated><id>https://www.sscit.de/2021/01/05/python-bazel</id><content type="html" xml:base="https://www.sscit.de/2021/01/05/python-bazel.html">&lt;p&gt;While working on &lt;a href=&quot;/2021/01/03/REL.html&quot;&gt;REL&lt;/a&gt;, I learned a lot about Bazel and its usage as build system in open source projects. In a series of blog posts, I will share these learnings and describe different approaches. Today’s blog post addresses the integration of C++-based Python modules into Bazel and the modelling of dependencies towards the corresponding Python-based tests.&lt;/p&gt;

&lt;p&gt;As part of REL’s Python integration, I created a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cc_library&lt;/code&gt; called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rel_py&lt;/code&gt; which includes the core REL C++ library and the necessary Python binding (using the ingenious &lt;a href=&quot;https://github.com/pybind/pybind11&quot;&gt;pybind11&lt;/a&gt; framework). If the library is built as dynamic library, the resulting &lt;em&gt;librel_py.so&lt;/em&gt; file can directly be imported in every Python script via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;import&lt;/code&gt; statement. It took me quite some time, though, to model the dependency between a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;py_test&lt;/code&gt; rule and the mentioned &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cc_library&lt;/code&gt;. My goal was to add an integration test to Bazel, which uses REL within Python, to read a toy model and test the basic functionality, like accessing all type instances, checking the API etc.&lt;/p&gt;

&lt;p&gt;The integration test itself is a simple python script, that imports &lt;em&gt;librel_py.so&lt;/em&gt; and interacts with the API. I wrapped it into a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;py_test&lt;/code&gt; rule. At the moment, it is not possible, though, to model a dependency (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;deps&lt;/code&gt;) in Bazel from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;py_test&lt;/code&gt; towards &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cc_library&lt;/code&gt;, as Bazel only allows dependencies towards rules from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;py_&lt;/code&gt; family. Therefore I tried the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data&lt;/code&gt; - attribute, which allows specifying arbitrary dependencies, e.g. to test data. Unfortunately, with this approach, I was not able to specify the correct import paths for the Python runtime. During test execution, Python always complained, that the module that shall be imported cannot be found.&lt;/p&gt;

&lt;p&gt;After searching on Stackoverflow and the Bazel bugtracker, I finally figured out the following approach, to get the dependencies right: Apparently it is necessary to define a dummy &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;py_library&lt;/code&gt; first, which is modeled as dependency within the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;py_test&lt;/code&gt;. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;py_library&lt;/code&gt; then uses the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;data&lt;/code&gt; attribute to point to a &lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cc_binary&lt;/code&gt;&lt;/strong&gt; rule, which is located in the &lt;strong&gt;same folder&lt;/strong&gt; as the two py-rules, and is actually a copy of the original &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cc_library&lt;/code&gt;. The disadvantage of this solution is definitely, that the Bazel model is partially duplicated. Nevertheless, the obvious advantage, it now works and I can run an integration test via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bazel test&lt;/code&gt;, that builds the Python binding library/binary of REL and runs a Python script, to test the functionality.&lt;/p&gt;

&lt;p&gt;My solution in Bazel can be found here: &lt;a href=&quot;https://github.com/sscit/rel/blob/main/relpy/test/BUILD&quot;&gt;https://github.com/sscit/rel/blob/main/relpy/test/BUILD&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Bazel Bugtracker issues related to this topic, that contain additional details:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/bazelbuild/bazel/issues/1475&quot;&gt;https://github.com/bazelbuild/bazel/issues/1475&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/bazelbuild/bazel/issues/701&quot;&gt;https://github.com/bazelbuild/bazel/issues/701&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Stefan Schlichthärle</name></author><summary type="html">While working on REL, I learned a lot about Bazel and its usage as build system in open source projects. In a series of blog posts, I will share these learnings and describe different approaches. Today’s blog post addresses the integration of C++-based Python modules into Bazel and the modelling of dependencies towards the corresponding Python-based tests.</summary></entry></feed>